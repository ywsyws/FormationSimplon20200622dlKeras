{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/emnist_ab/images_train.npy\")\n",
    "y = np.load(\"data/emnist_ab/labels_train.npy\")\n",
    "X_test = np.load(\"data/emnist_ab/images_test.npy\")\n",
    "y_test = np.load(\"data/emnist_ab/labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10\n",
       "0    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts() # Seulement dix images de chaque classe !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faut séparer encore le train en deux (créer un validation set) pour pouvoir vérifier que l'on overfit pas trop\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff2a5b27710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on tente d'entraîner un modèle d'une taille importante sur les 10 images dont on dispose, il tombera dans le sur-apprentissage très rapidement.\n",
    "\n",
    "Il faut donc utiliser plusieurs méthodes pour limiter cela :\n",
    "- Utiliser un modèle avec peu de paramètres / très régularisé : Vous pouvez utiliser `model.summary()` pour vérifier le nombre de paramètres entraînables du modèle, il doit être petit afin de limiter l'overfitting.\n",
    "- Utiliser le validation set pour arrêter l'entraînement quand la loss sur le validation set commence à remonter : cela s'appelle l'Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire et compiler ici votre modèle.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Dense(28, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='linear'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 28)                21980     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 58        \n",
      "=================================================================\n",
      "Total params: 22,038\n",
      "Trainable params: 22,038\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Afficher ici le summary du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 72.8511 - accuracy: 0.4000 - val_loss: 27.9871 - val_accuracy: 0.7000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 27.9101 - accuracy: 0.6000 - val_loss: 27.9628 - val_accuracy: 0.7000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.2786 - accuracy: 0.9000 - val_loss: 32.9635 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff280364550>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraîner ici votre modèle\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 1ms/step - loss: 34.3016 - accuracy: 0.6551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[34.3016242980957, 0.6550502181053162]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation du modèle\n",
    "## Attention : dans cette mise en situation, l'entreprise n'a accès qu'à très peu d'images, c'est le coeur du problème.\n",
    "## Le test set que nous utilisons dans ce notebook n'existe donc pas dans la mise en situation.\n",
    "## Il représente le monde réel et tous les autres A et B que l'algorithme devra traiter après avoir été entraîné.\n",
    "## Il faut donc l'utiliser le moins de fois possible dans cet exercice et il ne doit surtout pas être utilisé\n",
    "## pour décider quel modèle utiliser.\n",
    "## Pour cela, fiez-vous à votre validation set.\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chez moi, le modèle atteint déjà une accuracy de 60-65%. C'est déjà la preuve qu'il apprend mais on peut faire mieux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec data augmentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisez tf.keras.preprocessing.image.ImageDataGenerator pour créer un objet \"generator\" qui permettra\n",
    "# de modifier légèrement les images à chaque epoch d'entraînement.\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construisez ici un modèle avec plus de paramètres que le précédent :\n",
    "# Grâce à la data augmentation, il va beaucoup moins overfitter que le précédent.\n",
    "model2 = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "        tf.keras.layers.Dense(28, activation='relu'),\n",
    "        tf.keras.layers.Dense(14, activation='relu'),\n",
    "        tf.keras.layers.Dense(7, activation='relu'),\n",
    "        tf.keras.layers.Dense(2, activation='linear'),\n",
    "])\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7537 - accuracy: 0.6000 - val_loss: 41.7991 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6655 - accuracy: 0.7000 - val_loss: 41.9492 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8106 - accuracy: 0.6000 - val_loss: 34.5210 - val_accuracy: 0.2000\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7538 - accuracy: 0.4000 - val_loss: 24.8822 - val_accuracy: 0.2000\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7088 - accuracy: 0.3000 - val_loss: 20.7568 - val_accuracy: 0.3000\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5790 - accuracy: 0.7000 - val_loss: 16.8916 - val_accuracy: 0.3000\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7643 - accuracy: 0.6000 - val_loss: 15.5564 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7322 - accuracy: 0.6000 - val_loss: 16.3494 - val_accuracy: 0.7000\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5394 - accuracy: 0.7000 - val_loss: 15.6439 - val_accuracy: 0.7000\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4831 - accuracy: 0.8000 - val_loss: 17.3205 - val_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5492 - accuracy: 0.8000 - val_loss: 19.1891 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4394 - accuracy: 0.8000 - val_loss: 19.8320 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff29c19a8d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînez ici votre modèle en utilisant generator.flow(X_train, y_train)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "model2.fit_generator(\n",
    "    datagen.flow(X_train,y_train, batch_size=4),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 1ms/step - loss: 10.5480 - accuracy: 0.7076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.54796028137207, 0.7076196074485779]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Une fois satisfaits de votre performance sur le validation set, évaluez une seule fois sur le test set\n",
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a déjà atteint une bien meilleure performance grâce à l'augmentation de données. En effet, celle-ci limite beaucoup l'overfitting et nous permet donc d'utiliser un modèle bien plus gros.\n",
    "\n",
    "Chez moi, l'accuracy atteint 70-80%.\n",
    "\n",
    "Mais l'on peut vraisemblablement faire encore mieux en combinant cette approche à du transfer learning. Pour ce faire, on va utilser le modèle entraîné précédemment sur le jeu de données MNIST (reconnaissance de chiffres), retirer sa dernière couche et la remplacer par une couche Dense(1) afin qu'elle soit adaptée au problème actuel.\n",
    "\n",
    "Nous allons ensuite réentraîner le modèle ainsi modifié, en rendant ses couches inférieures non-entraînables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez ici le modèle entraîné précédemment sur MNIST\n",
    "base_model = tf.keras.models.load_model(filepath=\"models/mnist_model.h5\")\n",
    "\n",
    "# Enlevez la dernière couche avec model.pop()\n",
    "base_model.layers.pop()\n",
    "\n",
    "# Rendez le modèle non entraînable\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons un nouveau modèle à partir de cet ancien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construisez et compilez ici votre modèle de transfer learning en rajoutant au modèle mnist une couche Dense(1).\n",
    "\n",
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = tf.keras.layers.Dense(2)(x)\n",
    "transfered_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "transfered_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 6.0121 - accuracy: 0.5000 - val_loss: 35.9042 - val_accuracy: 0.9000\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 5.3601 - accuracy: 0.5000 - val_loss: 33.8211 - val_accuracy: 0.9000\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 6.2097 - accuracy: 0.6000 - val_loss: 33.6680 - val_accuracy: 0.9000\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 9.8207 - accuracy: 0.6000 - val_loss: 32.5720 - val_accuracy: 0.9000\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8973 - accuracy: 0.9000 - val_loss: 31.2258 - val_accuracy: 0.9000\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 5.0183 - accuracy: 0.6000 - val_loss: 30.3927 - val_accuracy: 0.9000\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 6.7322 - accuracy: 0.6000 - val_loss: 29.7881 - val_accuracy: 0.9000\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.2375 - accuracy: 0.6000 - val_loss: 28.8510 - val_accuracy: 0.9000\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 8.9741 - accuracy: 0.6000 - val_loss: 28.1825 - val_accuracy: 0.9000\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 8.7314 - accuracy: 0.4000 - val_loss: 28.5648 - val_accuracy: 0.9000\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 4.5407 - accuracy: 0.7000 - val_loss: 29.6150 - val_accuracy: 0.9000\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 6.7115 - accuracy: 0.6000 - val_loss: 30.3015 - val_accuracy: 0.9000\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4947 - accuracy: 0.6000 - val_loss: 31.0294 - val_accuracy: 0.9000\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4.6874 - accuracy: 0.6000 - val_loss: 31.4025 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff269714e48>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînez ici votre modèle. A vous de voir si vous utilisez encore la data augmentation ou si vous gardez X_train et y_train sans les changer.\n",
    "transfered_model.fit_generator(\n",
    "    datagen.flow(X_train,y_train, batch_size=4),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 1s 5ms/step - loss: 264.3300 - accuracy: 0.7986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[264.3299865722656, 0.7985823750495911]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Une fois satisfaits de votre performance sur le validation set, évaluez une seule fois sur le test set\n",
    "transfered_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chez moi, la performance est comparable au modèle avec data augmentation.\n",
    "\n",
    "Cela peut s'expliquer par le fait que la tâche de reconnaissance des A et des B n'est pas très difficile et la data augmentation suffit à recouvrir une grande partie des cas possibles. Si on avait choisi une tâche plus difficile (par exemple reconnaître les 26 lettres de l'alphabet, je pense que le transfer learning aurait mieux fonctionné que la data augmentation seule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
