{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/emnist/images.npy\")\n",
    "y = np.load(\"data/emnist/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_X = X[y<=2, ...]\n",
    "AB_y = y[y<=2] - 1 # 0 si c'est un A, 1 si c'est un B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(AB_X, AB_y, train_size=20, stratify=AB_y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/emnist_ab/images_test.npy\", X_test)\n",
    "np.save(\"data/emnist_ab/labels_test.npy\", y_test)\n",
    "np.save(\"data/emnist_ab/images_train.npy\", X_train)\n",
    "np.save(\"data/emnist_ab/labels_train.npy\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/emnist_ab/images_train.npy\")\n",
    "y = np.load(\"data/emnist_ab/labels_train.npy\")\n",
    "X_test = np.load(\"data/emnist_ab/images_test.npy\")\n",
    "y_test = np.load(\"data/emnist_ab/labels_test.npy\")\n",
    "X, X_test = map(lambda x: x/255.0, (X, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10\r\n",
       "0    10\r\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts() # Seulement dix images de chaque classe !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faut séparer encore le train en deux (créer un validation set) pour pouvoir vérifier que l'on overfit pas trop\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage object at 0x0000029833F2C130>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARc0lEQVR4nO3de3DV5ZkH8O/3hFw0ASUgGiGAVZQyVFBT1GW39bJrLdMZ8Dqy1aUdu4iju3aGna7jTqd2Z/9wdmqtdbbWuKK4Q+lq0cJ03a0UZRw7igTkfqlWAQPhZhYNAUKS8+wfOXSj5n1OPPeT9/uZyZzkPOfNeTjkm9/Jec/7e2lmEJGhL1HsBkSkMBR2kUgo7CKRUNhFIqGwi0RiWCHvrIrVVoPaQt6lSFROoBMnrYsD1bIKO8nrATwKoALAv5vZQ97ta1CLy3ltNncpIo41tipYy/hpPMkKAP8G4OsApgCYS3JKpt9PRPIrm7/ZZwB418zeM7OTAH4JYHZu2hKRXMsm7GMBfNDv69bUdZ9Acj7JFpIt3ejK4u5EJBvZhH2gFwE+895bM2s2syYza6pEdRZ3JyLZyCbsrQAa+309DsC+7NoRkXzJJuxrAUwieR7JKgC3AViRm7ZEJNcynnozsx6S9wL4Lfqm3haZ2dacdSYiOZXVPLuZvQTgpRz1IiJ5pLfLikRCYReJhMIuEgmFXSQSCrtIJBR2kUgo7CKRUNhFIqGwi0RCYReJhMIuEgmFXSQSCrtIJAp6KmkpP6ysKtp9W2+vf4Nkmrp8go7sIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkNM8+FCQqwqXa092hPdPOd+sfXHeaW++u+8wmQIPGpF8ftWnAnYf/pH7ZJree7Oz8vC0NaTqyi0RCYReJhMIuEgmFXSQSCrtIJBR2kUgo7CKR0Dx7GUjU1rr19psuDtYOzuxxxy74s9Vu/W/OeNutD09k/iPUC3+Ofvk3Gt36IyNudevnLNoQrCWPHXPHDkVZhZ3kLgAdAHoB9JhZUy6aEpHcy8WR/WozO5yD7yMieaS/2UUikW3YDcDLJNeRnD/QDUjOJ9lCsqUbXVnenYhkKtun8TPNbB/JMQBWktxhZq/1v4GZNQNoBoARrM981YSIZCWrI7uZ7UtdHgTwIoAZuWhKRHIv47CTrCU5/NTnAK4DsCVXjYlIbmXzNP5sAC+SPPV9fmFm/5OTrspMunOrJ+rP9MefVuPWW+eMc+sLFzwXrN1Y1+qOPWH+uddfOT7WrXf0+uvdK5xF61Oq97pj0/W+Z/4rbv23e78arI1Y63/vnr373Dqs/P4izTjsZvYegGk57EVE8khTbyKRUNhFIqGwi0RCYReJhMIuEgktcc2BxAUT3Pr2hWe49cbGD936E5Mec+uXVYdrb58Mn2YaAL617jtuveFx55sDqGw/4dZRET4d9KFLh7tDL5q3w63/dPxv3PoFDx0I1r6/brY79sLvuWX0tPrThqVIR3aRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBKaZx8shueLu84d4Q79l7940a3fXLffrSfS/E5+oys8l/7tX9/jjp38U38pZ8/uD9y6ZbHUc8w2fzvpNVPCp8gGgJoJ/+3Wb6kLv3/hyPSV7thfn3WVW4fm2UWkVCnsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBKaZz/FmUcHgMTFk4O1w3/nb//7tdP3pLlz/1TUSzvOdusP/zy8dfHkX+12xxZzXbZ1+9tJI3wW6qy1nqx364mTfm/+CbhLk47sIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkNM+eMmxCo1t///vhNeOrL3siq/u+ftvNbr1zyblu/dznNwZrPZ2dGfU0FHRZeK58yVtXuGMn7/HPWV+O0h7ZSS4ieZDkln7X1ZNcSfKd1OXI/LYpItkazNP4ZwBc/6nr7gewyswmAViV+lpESljasJvZawDaP3X1bACLU58vBjAnx32JSI5l+gLd2WbWBgCpyzGhG5KcT7KFZEs3ujK8OxHJVt5fjTezZjNrMrOmSvibBIpI/mQa9gMkGwAgdXkwdy2JSD5kGvYVAOalPp8HYHlu2hGRfEk7z05yKYCrAIwm2QrgBwAeAvAcyTsB7AFwSz6bzIVh48a69R1/789lL70svEd6Nf3fmd/bd41bH/bP/trq+jfWuvVkT5p14SWKNf6fdck6f9V4uvPpf5Q8GaxV7/d/9O3E0Ht9KW3YzWxuoHRtjnsRkTzS22VFIqGwi0RCYReJhMIuEgmFXSQSQ2aJa6K21q233jzBrT8952dufZpztueHP5zujt35w6luveatTW7dynRqDYB7iu6e6Re4QxdcudqtV9P/8X3leEOwNu5Vf2rNusPTduVKR3aRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBLlNc+eCJ/Ouf2mi92hCxc859avrPaXUy47GjzzFp5v9hcAnvPqBree7Bp6yylPGTZ+XLD2/n3d7tg7z/Qft540W10/9serg7VR7/rnWynjdzYE6cguEgmFXSQSCrtIJBR2kUgo7CKRUNhFIqGwi0SirObZWRGeZ//o/PC6aQC46vRdbj2ZZrean+/+arB2zutH/O99/LhbL2cc5v8InZw4Olj76wvfcMeekahx6/+bPOHWD+0I3/fI9s3u2KFIR3aRSCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBLlNc/ubPHb1eCvjR6d8Nc+b0xzmvCjz4fPQV6zxd9SGWZ+vYSx0n/cjs6+xK0Pm38gWFswcp07NoHT3Prq4/422xN/E/6ZSHZ2umOHorRHdpKLSB4kuaXfdQ+S3EtyQ+pjVn7bFJFsDeZp/DMArh/g+kfMbHrq46XctiUiuZY27Gb2GoD2AvQiInmUzQt095LclHqaPzJ0I5LzSbaQbOnG0D3XmkipyzTsjwM4H8B0AG0AHg7d0MyazazJzJoq0yw2EZH8ySjsZnbAzHrNLAngSQAzctuWiORaRmEn2X8e6gYAW0K3FZHSkHaeneRSAFcBGE2yFcAPAFxFcjoAA7ALwF157PH/exkfnlf95ow33bHp9vLe1nWOWx/9dkewVs77p6fb1/7DW/zz8U/8zh/c+qKJ/xWs1SX8++61pFs/lvT/LKz8OPwaUfm+8yFzacNuZnMHuPqpPPQiInmkt8uKREJhF4mEwi4SCYVdJBIKu0gkymqJq3x+w8aNdeutN09w6+m2ur6xrtWt7+z2jif+uuKLq8KnDgeAyVVtbv3wtOHB2qj1/vdG0t/CuxzpyC4SCYVdJBIKu0gkFHaRSCjsIpFQ2EUiobCLRKKs5tltz75gbclbV7hjH5jln7Z4SvVet7736hHB2vhDje7Y3v0H3XrFmLP88aPPcOtWGf6dvWOuv4z06dk/c+uXVvnbIr9wdJxb/9GTtwZryUp3KBbd9ahb/2KVv7T4yJTwQtbRzvbfAGCaZxeRcqWwi0RCYReJhMIuEgmFXSQSCrtIJBR2kUiU1zz7ifCpgSs6/HnTbvjzppdU+VsTP3n3Y8HaP1x7izt2305/W+OGi/x5+DvGr3brNYnw1sRfqvbXm59V4a8p/8a22936sV+Et7IGgLHLNgdrdpG/ln7DPL8+pfI9t947PPx/7m3/DQDWnWYP7zKkI7tIJBR2kUgo7CKRUNhFIqGwi0RCYReJhMIuEonymmfvDc+bjtpId+xP/vIyt353/Vq3/uXq04K1VV/6T3ds91R/jj+R5nduEv7WxR3J8Lrup4/4/+6nfne1W7/wmSNuvWab/7glne2shx3wv/fi3f45Cm6fusutL7hydbD2u2kz3bGJ329067A0mz7T/3lMOz4P0h7ZSTaSfJXkdpJbSd6Xur6e5EqS76QuR+a/XRHJ1GCexvcAWGhmXwRwBYB7SE4BcD+AVWY2CcCq1NciUqLSht3M2sxsferzDgDbAYwFMBvA4tTNFgOYk68mRSR7n+sFOpITAVwCYA2As82sDej7hQBgTGDMfJItJFu6EX5vu4jk16DDTrIOwDIA3zWzjwc7zsyazazJzJoq4S8+EJH8GVTYSVaiL+hLzOyF1NUHSDak6g0A/KVbIlJUaafeSBLAUwC2m9mP+5VWAJgH4KHU5fK8dNifc3rf+l/5UyWvvzfDrT9741fc+txrfh+snVd9yB2bzvtd/qmk050mu3p/+L+x8eXj7tgL3w4vQQWAZGenW89G70H/cdu/zV8anG5K89tnbgjWnrjtGnfspJNT3TqT/tTZsbGnu/W6N3cFa70H8nPcHMw8+0wAdwDYTPLUo/cA+kL+HMk7AewB4C/qFpGiSht2M3sdQOgdAtfmth0RyRe9XVYkEgq7SCQUdpFIKOwikVDYRSJBK+BSuxGst8tZmi/gJ2r9rY05Mbw1cbIqu5XCiZP+1sPeVtWAf4rtkj4lcsI//feR2/33Rtz9wDK3fkPd7mDt3W7/vjecGO/WjyX9d4P+ZL0/jz/5/gPBWs9e///bs8ZW4WNrH3D2TEd2kUgo7CKRUNhFIqGwi0RCYReJhMIuEgmFXSQSZXUq6XxKu25768683be/KnsIc85PAAD1yza59cdxk1v/4czw+xe+efmb7thxVe1ufcnuL7v1huX+FuA9beF59nzRkV0kEgq7SCQUdpFIKOwikVDYRSKhsItEQmEXiYTWs0v5SrMePlEbPnc7x5/rjk13joKKwx+59Z69bW493XsMMqX17CKisIvEQmEXiYTCLhIJhV0kEgq7SCQUdpFIDGZ/9kYAzwI4B0ASQLOZPUryQQB/C+DUJtsPmNlL+WpU5DPSzFUnOzrCxSzPT+Cf6b80DebkFT0AFprZepLDAawjuTJVe8TMfpS/9kQkVwazP3sbgLbU5x0ktwMYm+/GRCS3Ptff7CQnArgEwJrUVfeS3ERyEcmRgTHzSbaQbOlGeJsiEcmvQYedZB2AZQC+a2YfA3gcwPkApqPvyP/wQOPMrNnMmsysqRL+/lgikj+DCjvJSvQFfYmZvQAAZnbAzHrNLAngSQD+LnwiUlRpw06SAJ4CsN3Mftzv+oZ+N7sBwJbctyciuTKYV+NnArgDwGaSG1LXPQBgLsnpAAzALgB35aVDEcmJwbwa/zqAgdbHak5dpIzoHXQikVDYRSKhsItEQmEXiYTCLhIJhV0kEgq7SCQUdpFIKOwikVDYRSKhsItEQmEXiYTCLhIJhV0kEgXdspnkIQC7+101GsDhgjXw+ZRqb6XaF6DeMpXL3iaY2VkDFQoa9s/cOdliZk1Fa8BRqr2Val+AestUoXrT03iRSCjsIpEodtibi3z/nlLtrVT7AtRbpgrSW1H/ZheRwin2kV1ECkRhF4lEUcJO8nqSO0m+S/L+YvQQQnIXyc0kN5BsKXIvi0geJLml33X1JFeSfCd1OeAee0Xq7UGSe1OP3QaSs4rUWyPJV0luJ7mV5H2p64v62Dl9FeRxK/jf7CQrAPwBwF8BaAWwFsBcM9tW0EYCSO4C0GRmRX8DBsmvADgK4Fkzm5q67l8BtJvZQ6lflCPN7B9LpLcHARwt9jbeqd2KGvpvMw5gDoBvoYiPndPXrSjA41aMI/sMAO+a2XtmdhLALwHMLkIfJc/MXgPQ/qmrZwNYnPp8Mfp+WAou0FtJMLM2M1uf+rwDwKltxov62Dl9FUQxwj4WwAf9vm5Fae33bgBeJrmO5PxiNzOAs82sDej74QEwpsj9fFrabbwL6VPbjJfMY5fJ9ufZKkbYB9pKqpTm/2aa2aUAvg7gntTTVRmcQW3jXSgDbDNeEjLd/jxbxQh7K4DGfl+PA7CvCH0MyMz2pS4PAngRpbcV9YFTO+imLg8WuZ8/KaVtvAfaZhwl8NgVc/vzYoR9LYBJJM8jWQXgNgAritDHZ5CsTb1wApK1AK5D6W1FvQLAvNTn8wAsL2Ivn1Aq23iHthlHkR+7om9/bmYF/wAwC32vyP8RwD8Vo4dAX18AsDH1sbXYvQFYir6ndd3oe0Z0J4BRAFYBeCd1WV9Cvf0HgM0ANqEvWA1F6u3P0fen4SYAG1Ifs4r92Dl9FeRx09tlRSKhd9CJREJhF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpH4P1uLLEeDmkuoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on tente d'entraîner un modèle d'une taille importante sur les 10 images dont on dispose, il tombera dans le sur-apprentissage très rapidement.\n",
    "\n",
    "Il faut donc utiliser plusieurs méthodes pour limiter cela :\n",
    "- Utiliser un modèle avec peu de paramètres : Vous pouvez utiliser `model.summary()` pour vérifier le nombre de paramètres entraînables du modèle, il doit être petit afin de limiter l'overfitting.\n",
    "- Utiliser le validation set pour arrêter l'entraînement quand la loss sur le validation set commence à remonter : cela s'appelle l'Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire et compiler ici votre modèle.\n",
    "basic_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(4, 3, activation=\"relu\", input_shape=(28, 28, 1), padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(4, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(1, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "basic_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 1)           37        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 50        \n",
      "=================================================================\n",
      "Total params: 275\n",
      "Trainable params: 275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Afficher ici le summary du modèle\n",
    "basic_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant `model.summary()`, vérifiez combien de paramètres entraînables a votre modèle.\n",
    "\n",
    "Essayez de faire en sorte que ce nombre ne dépasse pas 1000 !\n",
    "\n",
    "Pour réduire le nombre de paramètres (et donc l'overfitting), on peut utiliser divers éléments architecturaux comme les convolutions ou le MaxPooling par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6757 - accuracy: 0.5000 - val_loss: 0.7448 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6712 - accuracy: 0.5000 - val_loss: 0.7444 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6668 - accuracy: 0.5000 - val_loss: 0.7441 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6623 - accuracy: 0.5000 - val_loss: 0.7437 - val_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6580 - accuracy: 0.5000 - val_loss: 0.7436 - val_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6536 - accuracy: 0.6000 - val_loss: 0.7434 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6493 - accuracy: 0.6000 - val_loss: 0.7433 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6449 - accuracy: 0.6000 - val_loss: 0.7433 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History object at 0x0000029846B80AC0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraîner ici votre modèle\n",
    "basic_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 1s 3ms/step - loss: 0.6873 - accuracy: 0.5557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6872542500495911, 0.5556703805923462]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation du modèle\n",
    "# Attention : le test set doit être utilisé le moins de fois possible afin de ne pas overfitter dessus.\n",
    "# Ne faites donc pas plusieurs essais jusqu'à avoir un bon score sur le test set mais fiez-vous à votre validation set.\n",
    "# En effet, le test set représente \"la réalité\", ce à quoi vous n'avez pas accès, et en pratique, vous n'aurez droit qu'à un seul essai.\n",
    "basic_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chez moi, le modèle atteint déjà une accuracy de 60-65%. C'est déjà la preuve qu'il apprend mais on peut faire mieux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec data augmentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 8)         1160      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 4)         292       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                50192     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 75,101\n",
      "Trainable params: 75,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Utilisez tf.keras.preprocessing.image.ImageDataGenerator pour créer un objet generator\n",
    "generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=2,\n",
    "    height_shift_range=2,\n",
    "    shear_range=10,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    ")\n",
    "generator.fit(X_train)\n",
    "\n",
    "# Construisez ici un modèle avec plus de paramètres que le précédent :\n",
    "# Grâce à la data augmentation, il va beaucoup moins overfitter que le précédent.\n",
    "aug_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(28, 28, 1), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(8, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(4, 3, activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "aug_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "aug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6907 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6857 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6742 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6615 - accuracy: 0.5000 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6410 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5957 - accuracy: 0.6000 - val_loss: 0.6930 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5325 - accuracy: 0.8000 - val_loss: 0.7013 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5243 - accuracy: 0.8000 - val_loss: 0.6951 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3847 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3067 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2049 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 1.1464 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 2.3070 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History object at 0x0000029846AC5F70>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînez ici votre modèle en utilisant generator.flow(X_train, y_train)\n",
    "aug_model.fit(\n",
    "    generator.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3755776584148407, 0.8687241673469543]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a déjà atteint une bien meilleure performance grâce à l'augmentation de données. En effet, celle-ci limite beaucoup l'overfitting et nous permet donc d'utiliser un modèle bien plus gros.\n",
    "\n",
    "Mais l'on peut vraisemblablement faire encore mieux en combinant cette approche à du transfer learning. Pour ce faire, on va utilser le modèle entraîné précédemment sur le jeu de données MNIST (reconnaissance de chiffres), retirer sa dernière couche et la remplacer par une couche Dense(1) afin qu'elle soit adaptée au problème actuel.\n",
    "\n",
    "Nous allons ensuite réentraîner le modèle ainsi modifié, en rendant ses couches inférieures non-entraînables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer par le chemin de votre modèle\n",
    "mnist_model = tf.keras.models.load_model(\"models/mnist_model.h5\")\n",
    "mnist_model.pop() # On enlève la dernière couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 1)           73        \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                3200      \n",
      "=================================================================\n",
      "Total params: 3,937\n",
      "Trainable params: 3,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons un nouveau modèle à partir de cet ancien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 3.4541 - accuracy: 0.5000 - val_loss: 4.0895 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.9195 - accuracy: 0.5000 - val_loss: 4.0248 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5493 - accuracy: 0.5000 - val_loss: 3.9609 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0619 - accuracy: 0.5000 - val_loss: 3.8982 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0273 - accuracy: 0.5000 - val_loss: 3.8353 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.2765 - accuracy: 0.5000 - val_loss: 3.7718 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.7623 - accuracy: 0.5000 - val_loss: 3.7079 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.8109 - accuracy: 0.5000 - val_loss: 3.6448 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.9329 - accuracy: 0.5000 - val_loss: 3.5822 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 3.4894 - accuracy: 0.5000 - val_loss: 3.5190 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.6895 - accuracy: 0.5000 - val_loss: 3.4556 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.9866 - accuracy: 0.5000 - val_loss: 3.3926 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 3.3746 - accuracy: 0.5000 - val_loss: 3.3291 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 2.9895 - accuracy: 0.5000 - val_loss: 3.2657 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.7722 - accuracy: 0.5000 - val_loss: 3.2029 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.8000 - accuracy: 0.6000 - val_loss: 3.1407 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.5472 - accuracy: 0.5000 - val_loss: 3.0783 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.1939 - accuracy: 0.5000 - val_loss: 3.0160 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.7531 - accuracy: 0.6000 - val_loss: 2.9535 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4432 - accuracy: 0.5000 - val_loss: 2.8912 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.8508 - accuracy: 0.5000 - val_loss: 2.8292 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.6187 - accuracy: 0.5000 - val_loss: 2.7673 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.0042 - accuracy: 0.5000 - val_loss: 2.7058 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4974 - accuracy: 0.6000 - val_loss: 2.6448 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.8184 - accuracy: 0.5000 - val_loss: 2.5840 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.1784 - accuracy: 0.6000 - val_loss: 2.5243 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.9547 - accuracy: 0.5000 - val_loss: 2.4660 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6785 - accuracy: 0.6000 - val_loss: 2.4083 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1348 - accuracy: 0.7000 - val_loss: 2.3516 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.9742 - accuracy: 0.6000 - val_loss: 2.2951 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.2236 - accuracy: 0.5000 - val_loss: 2.2384 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0600 - accuracy: 0.7000 - val_loss: 2.1838 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1714 - accuracy: 0.7000 - val_loss: 2.1300 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4908 - accuracy: 0.8000 - val_loss: 2.0790 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.1963 - accuracy: 0.6000 - val_loss: 2.0280 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0044 - accuracy: 0.6000 - val_loss: 1.9783 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6132 - accuracy: 0.6000 - val_loss: 1.9283 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1857 - accuracy: 0.5000 - val_loss: 1.8770 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0394 - accuracy: 0.7000 - val_loss: 1.8270 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8221 - accuracy: 0.6000 - val_loss: 1.7794 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.4339 - accuracy: 0.6000 - val_loss: 1.7318 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0767 - accuracy: 0.6000 - val_loss: 1.6849 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2003 - accuracy: 0.7000 - val_loss: 1.6385 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0117 - accuracy: 0.5000 - val_loss: 1.5932 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8443 - accuracy: 0.6000 - val_loss: 1.5498 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8808 - accuracy: 0.6000 - val_loss: 1.5068 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0627 - accuracy: 0.6000 - val_loss: 1.4645 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8498 - accuracy: 0.6000 - val_loss: 1.4222 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0261 - accuracy: 0.7000 - val_loss: 1.3802 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4996 - accuracy: 0.7000 - val_loss: 1.3399 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4974 - accuracy: 0.7000 - val_loss: 1.3012 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1333 - accuracy: 0.5000 - val_loss: 1.2633 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5292 - accuracy: 0.8000 - val_loss: 1.2271 - val_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9161 - accuracy: 0.7000 - val_loss: 1.1923 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2874 - accuracy: 0.9000 - val_loss: 1.1599 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6070 - accuracy: 0.6000 - val_loss: 1.1278 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8540 - accuracy: 0.8000 - val_loss: 1.0969 - val_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4346 - accuracy: 0.7000 - val_loss: 1.0683 - val_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3188 - accuracy: 0.8000 - val_loss: 1.0412 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4904 - accuracy: 0.7000 - val_loss: 1.0155 - val_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6988 - accuracy: 0.6000 - val_loss: 0.9899 - val_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5451 - accuracy: 0.7000 - val_loss: 0.9648 - val_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6592 - accuracy: 0.7000 - val_loss: 0.9409 - val_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5154 - accuracy: 0.9000 - val_loss: 0.9208 - val_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5640 - accuracy: 0.8000 - val_loss: 0.9002 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1315 - accuracy: 0.8000 - val_loss: 0.8816 - val_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6793 - accuracy: 0.7000 - val_loss: 0.8629 - val_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.1907 - accuracy: 0.4000 - val_loss: 0.8464 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0671 - accuracy: 0.6000 - val_loss: 0.8309 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7802 - accuracy: 0.6000 - val_loss: 0.8164 - val_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4389 - accuracy: 0.8000 - val_loss: 0.8036 - val_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1973 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2352 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5425 - accuracy: 0.7000 - val_loss: 0.7695 - val_accuracy: 0.6000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4398 - accuracy: 0.7000 - val_loss: 0.7590 - val_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4383 - accuracy: 0.8000 - val_loss: 0.7477 - val_accuracy: 0.7000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7982 - accuracy: 0.7000 - val_loss: 0.7354 - val_accuracy: 0.7000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4166 - accuracy: 0.9000 - val_loss: 0.7258 - val_accuracy: 0.7000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1852 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.7000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2638 - accuracy: 0.9000 - val_loss: 0.7097 - val_accuracy: 0.7000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6541 - accuracy: 0.9000 - val_loss: 0.7013 - val_accuracy: 0.7000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4465 - accuracy: 0.8000 - val_loss: 0.6939 - val_accuracy: 0.7000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2173 - accuracy: 0.9000 - val_loss: 0.6881 - val_accuracy: 0.7000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6691 - accuracy: 0.8000 - val_loss: 0.6808 - val_accuracy: 0.7000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3074 - accuracy: 0.9000 - val_loss: 0.6734 - val_accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6661 - accuracy: 0.8000 - val_loss: 0.6655 - val_accuracy: 0.7000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8128 - accuracy: 0.7000 - val_loss: 0.6600 - val_accuracy: 0.7000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5853 - accuracy: 0.8000 - val_loss: 0.6550 - val_accuracy: 0.7000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4054 - accuracy: 0.8000 - val_loss: 0.6505 - val_accuracy: 0.7000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1617 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.7000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4805 - accuracy: 0.9000 - val_loss: 0.6442 - val_accuracy: 0.7000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2538 - accuracy: 0.9000 - val_loss: 0.6417 - val_accuracy: 0.7000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 0.6400 - val_accuracy: 0.7000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9471 - accuracy: 0.8000 - val_loss: 0.6361 - val_accuracy: 0.7000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1622 - accuracy: 0.9000 - val_loss: 0.6334 - val_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6156 - accuracy: 0.8000 - val_loss: 0.6291 - val_accuracy: 0.7000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1949 - accuracy: 0.8000 - val_loss: 0.6224 - val_accuracy: 0.7000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7151 - accuracy: 0.9000 - val_loss: 0.6160 - val_accuracy: 0.7000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4163 - accuracy: 0.8000 - val_loss: 0.6082 - val_accuracy: 0.7000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7774 - accuracy: 0.7000 - val_loss: 0.6010 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History object at 0x0000029A2A4783D0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.trainable = False\n",
    "transfer_model = tf.keras.Sequential([\n",
    "    mnist_model,\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "transfer_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "transfer_model.fit(\n",
    "    generator.flow(X_train, y_train, batch_size=32),\n",
    "    #X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 1s 4ms/step - loss: 0.8177 - accuracy: 0.6883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.817651093006134, 0.6882752776145935]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chez moi, la performance est comparable au modèle avec data augmentation.\n",
    "\n",
    "Cela peut s'expliquer par le fait que la tâche de reconnaissance des A et des B n'est pas très difficile et la data augmentation suffit à recouvrir une grande partie des cas possibles. Si on avait choisi une tâche plus difficile (par exemple reconnaître les 26 lettres de l'alphabet, je pense que le transfer learning aurait mieux fonctionné que la data augmentation seule."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
